{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import heapq\n",
    "from collections import defaultdict, Counter\n",
    "import struct\n",
    "import sys\n",
    "from scipy.fftpack import dct, idct\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções úteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEntropy(image):\n",
    "    hist = cv2.calcHist([image],[0],None,[256],[0,256])\n",
    "    hist = hist.ravel()/hist.sum()\n",
    "    logs = np.log2(hist+0.00001)\n",
    "    entropy = -1 * (hist*logs).sum()\n",
    "    return entropy\n",
    "\n",
    "def divideImageIntoSubImages(image, subImageSize):\n",
    "    subImages = []\n",
    "    for i in range(0, image.shape[0], subImageSize):\n",
    "        for j in range(0, image.shape[1], subImageSize):\n",
    "            subImages.append(image[i:i+subImageSize, j:j+subImageSize])\n",
    "    return np.array(subImages)\n",
    "\n",
    "def reconstructImage(subimages, originalImageShape):\n",
    "    image = np.zeros(originalImageShape)\n",
    "    idx = 0\n",
    "    for i in range(0, originalImageShape[0], subimages[0].shape[0]):\n",
    "        for j in range(0, originalImageShape[1], subimages[0].shape[1]):\n",
    "            image[i:i+subimages[0].shape[0], j:j+subimages[0].shape[1]] = subimages[idx]\n",
    "            idx += 1\n",
    "    return image\n",
    "\n",
    "def getNumberOfDifferentColors(img):\n",
    "    return len(np.unique(img))\n",
    "\n",
    "def plotImage(img, title):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_IMAGE = cv2.imread('./imagens/unequal.pgm',0)\n",
    "ORIGINAL_IMAGE_SHAPE = ORIGINAL_IMAGE.shape\n",
    "plotImage(ORIGINAL_IMAGE, 'Imagem Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBIMAGES = divideImageIntoSubImages(ORIGINAL_IMAGE, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tirar os residuos/  Pegar os resíduos e transformar na imagem original - Giovana "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def generate_macroblocks(img, block_size):\n",
    "    \"\"\"\n",
    "    Generates macroblocks of a given size from the image.\n",
    "    \"\"\"\n",
    "    for y in range(0, img.shape[0], block_size):\n",
    "        for x in range(0, img.shape[1], block_size):\n",
    "            macroblock = img[y:y+block_size, x:x+block_size]\n",
    "            yield y, x, macroblock\n",
    "\n",
    "def get_vertical_prediction(macroblock,left_column = None):\n",
    "    \"\"\"\n",
    "    Applies a predictive function without loss on each macro block based on\n",
    "    the formula f(x, y) = f(x, y) - f(x, y - 1).\n",
    "    \"\"\"\n",
    "    new_block = np.zeros_like(macroblock, dtype=float)\n",
    "    if left_column is not None:\n",
    "        new_block[:,:] = left_column\n",
    "    else: \n",
    "        new_block[:,0] = 0\n",
    "        new_block[:,1:] = macroblock[:,0].reshape(-1, 1) \n",
    "    # print(new_block,left_column)\n",
    "    # new_block[:,:] = macroblock[:,0:]\n",
    "    return new_block\n",
    "\n",
    "def get_horizontal_prediction(macroblock, top_row=None):\n",
    "    \"\"\"\n",
    "    Applies a vertical predictive function on a given macroblock based on the formula\n",
    "    f(x, y) = f(x, y) - f(x-1, y). \n",
    "    \"\"\"\n",
    "    new_block = np.zeros_like(macroblock, dtype=float)\n",
    "    if top_row is not None:\n",
    "        new_block[:,:] = top_row.reshape(-1, 1) \n",
    "    else: \n",
    "        new_block[0,:] = 0\n",
    "        new_block[1:,:] = macroblock[0,:].reshape(1, -1) \n",
    "    \n",
    "    # new_block[1:,:] = macroblock[0:-1,:]\n",
    "    \n",
    "    return new_block\n",
    "\n",
    "def get_mean_prediction(macroblock,left_column,top_row):\n",
    "\n",
    "    block_size = macroblock.shape[0]\n",
    "    new_block = np.zeros_like(macroblock, dtype=float)\n",
    "\n",
    "    if left_column is not None and top_row is not None:\n",
    "        mean_value = int((np.sum(top_row) + np.sum(left_column)) / (2 * block_size))\n",
    "        new_block = np.full((block_size, block_size), mean_value)\n",
    "\n",
    "    return new_block\n",
    "\n",
    "def calculate_entropy(block):\n",
    "    \"\"\"\n",
    "    Calculates the entropy of the given block.\n",
    "    \"\"\"\n",
    "    # Flatten the block and calculate the probability distribution\n",
    "    flattened_block = block.flatten()\n",
    "    value_counts = Counter(flattened_block)\n",
    "    \n",
    "    # Calculate the probabilities of each unique value\n",
    "    total_count = sum(value_counts.values())\n",
    "    probabilities = np.array([count / total_count for count in value_counts.values()])\n",
    "    \n",
    "    # Calculate entropy\n",
    "    return entropy(probabilities, base=2)\n",
    "\n",
    "def get_best_prediction(original_block,block_vertical, block_horizontal,block_mean):\n",
    "    \"\"\"\n",
    "    Compares two blocks by calculating their entropy and returns the block\n",
    "    with the lowest entropy along with an indicator of which block was chosen.\n",
    "    \"\"\"\n",
    "    # Calculate entropy for both blocks\n",
    "    entropy_vertical = calculate_entropy(block_vertical)\n",
    "    entropy_horizontal = calculate_entropy(block_horizontal)\n",
    "    entropy_mean = calculate_entropy(block_mean)\n",
    "    \n",
    "    # Find the block with the minimum entropy\n",
    "    entropies = [entropy_vertical, entropy_horizontal, entropy_mean]\n",
    "    blocks = [block_vertical, block_horizontal, block_mean]\n",
    "    min_entropy_index = entropies.index(min(entropies))\n",
    "    \n",
    "    # Return the block with the lowest entropy and its index\n",
    "    return blocks[min_entropy_index],min_entropy_index\n",
    "    \n",
    "def process_image(img, block_size):\n",
    "    \"\"\"\n",
    "    Processes the entire image by dividing it into macroblocks,\n",
    "    applying the predictive function to each block, and \n",
    "    reconstructing the output image.\n",
    "    \"\"\"\n",
    "    options = []  # To store the choice of predictive function (0 or 1)\n",
    "    pred_img = np.zeros_like(img, dtype=float)\n",
    "    \n",
    "    # Iterate over each macroblock in the image\n",
    "    for y, x, macroblock in generate_macroblocks(img, block_size):\n",
    "        # Get left column and top row from the last macroblock for prediction\n",
    "        left_column = img[y:y+block_size,x-1] if (x > 0) else None\n",
    "        top_row = img[y-1, x:x+block_size] if (y > 0) else None\n",
    "\n",
    "        block_vertical   = macroblock - get_vertical_prediction(macroblock,left_column) \n",
    "        block_horizontal = macroblock - get_horizontal_prediction(macroblock,top_row)\n",
    "        block_mean = macroblock - get_mean_prediction(macroblock,left_column,top_row)\n",
    "\n",
    "\n",
    "\n",
    "        # Select the best prediction based on entropy\n",
    "        new_block, option = get_best_prediction(macroblock,block_vertical, block_horizontal,block_mean) ## testar remover e calcular a entropia\n",
    "        options.append(option)\n",
    "\n",
    "        # Place the processed block back into the image\n",
    "        pred_img[y:y+block_size, x:x+block_size] = new_block\n",
    "\n",
    "    return pred_img, options\n",
    "\n",
    "def reconstruct_image(residual_img, block_size, pred_type):\n",
    "    \"\"\"\n",
    "    Reconstructs the original image from a residual image.\n",
    "    \"\"\"\n",
    "    # Create an empty array to store the reconstructed original image\n",
    "    original_img = np.zeros_like(residual_img, dtype=float)\n",
    "\n",
    "    i = 0\n",
    "    # Iterate over the image in blocks of size `block_size`\n",
    "    for y, x, residual_block in generate_macroblocks(residual_img, block_size):\n",
    "        left_column = original_img[y:y+block_size,x-1] if (x > 0) else None\n",
    "        top_row = original_img[y-1, x:x+block_size] if (y > 0) else None\n",
    "\n",
    "        reconstructed_block = np.zeros_like(residual_block, dtype=float)\n",
    "        \n",
    "        # Extract the current residual block\n",
    "        if pred_type[i] == 0:\n",
    "            reconstructed_block = get_vertical_prediction(residual_block, left_column)\n",
    "            \n",
    "        \n",
    "        elif pred_type[i] == 1:\n",
    "            reconstructed_block = get_horizontal_prediction(residual_block, top_row)\n",
    "\n",
    "        elif pred_type[i] == 2:\n",
    "            reconstructed_block = get_mean_prediction(residual_block,left_column, top_row)\n",
    "        \n",
    "        # Place the reconstructed block back into the image\n",
    "        original_img[y:y+block_size, x:x+block_size] = reconstructed_block + residual_block\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    return original_img\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_matrix = np.matrix([[16, 11, 10, 16, 24, 40, 51, 61], \n",
    "                [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "                [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "                [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "                [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "                [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "                [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "                [72, 92, 95, 98, 112, 100, 103, 99]]) /10\n",
    "\n",
    "def get_dct(img):\n",
    "    ''' \n",
    "    Get 2D Cosine Transform of Image\n",
    "    '''\n",
    "    return fftpack.dct(fftpack.dct(img.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "def get_idct(coefficients):\n",
    "    ''' \n",
    "    Get 2D Inverse Cosine Transform of Image\n",
    "    '''\n",
    "    return fftpack.idct(fftpack.idct(coefficients.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "def apply_image_transformation(img, block_size, transform_function):\n",
    "    '''\n",
    "    Apply block-wise DCT or IDCT to an image.\n",
    "    '''\n",
    "    size = img.shape\n",
    "    transformed_img = np.zeros(size, dtype=float)\n",
    "\n",
    "    for y, x, macroblock in generate_macroblocks(img, block_size):\n",
    "        transformed_img[y:y+block_size, x:x+block_size] = transform_function(macroblock)\n",
    "        \n",
    "\n",
    "    return transformed_img\n",
    "\n",
    "def apply_quantization(transformed_image,block_size):\n",
    "\n",
    "    size = transformed_image.shape\n",
    "    quantized_image = np.zeros(size, dtype=float)\n",
    "    \n",
    "    for y, x, macroblock in generate_macroblocks(transformed_image, block_size):\n",
    "        quantized_block = np.divide(macroblock, quantization_matrix)\n",
    "        quantized_block = np.round(quantized_block)\n",
    "        quantized_image[y:y+block_size, x:x+block_size] = quantized_block\n",
    "    return quantized_image.astype(int)\n",
    "\n",
    "def apply_dequantization(transformed_image,block_size):\n",
    "\n",
    "    size = transformed_image.shape\n",
    "    dequantized_image = np.zeros(size, dtype=float)\n",
    "\n",
    "    for y, x, macroblock in generate_macroblocks(transformed_image, block_size):\n",
    "        dequantized_block = np.multiply(macroblock, quantization_matrix)\n",
    "        dequantized_image[y:y+block_size, x:x+block_size] = dequantized_block\n",
    "\n",
    "    return dequantized_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compressao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "img = ORIGINAL_IMAGE.astype(np.float64) - 128\n",
    "\n",
    "residuals, options = process_image(img, block_size)\n",
    "transformed_residuals = apply_image_transformation(residuals, block_size, get_dct)\n",
    "quantized_residuals = apply_quantization(transformed_residuals,block_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descompressao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dequantized_residuals = apply_dequantization(quantized_residuals,block_size)\n",
    "residuals_ = apply_image_transformation(dequantized_residuals, block_size, get_idct)\n",
    "reconstructed_image = reconstruct_image(residuals_, block_size, options)\n",
    "reconstructed_image = reconstructed_image.astype(np.float64) + 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazer a tranformada/fazer a transformada inversa - Fernando\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dct_2d_manual(matrix):\n",
    " \n",
    "    N, M = matrix.shape\n",
    "    dct_result = np.zeros((N, M))\n",
    "    print(N,M)\n",
    "    for k1 in range(N):\n",
    "        for k2 in range(M):\n",
    "            sum_value = 0\n",
    "            for n1 in range(N):\n",
    "                for n2 in range(M):\n",
    "                    sum_value += matrix[n1, n2] * np.cos((np.pi/N)*(n1+0.5)*k1)*np.cos((np.pi/M)*(n2+0.5)*k2)\n",
    "\n",
    "            dct_result[k1, k2] = sum_value\n",
    "    \n",
    "    return dct_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import dct\n",
    "usando_scipy=dct(ORIGINAL_IMAGE, type=2, norm='ortho')\n",
    "plotImage(usando_scipy,'DCT SCIPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_manual = dct_2d_manual(ORIGINAL_IMAGE)\n",
    "plotImage(dct_manual,'DCT manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dct(img):\n",
    "    ''' \n",
    "    Get 2D Cosine Transform of Image\n",
    "    '''\n",
    "    return fftpack.dct(fftpack.dct(img.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "def get_idct(coefficients):\n",
    "    ''' \n",
    "    Get 2D Inverse Cosine Transform of Image\n",
    "    '''\n",
    "    return fftpack.idct(fftpack.idct(coefficients.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "def apply_image_transform(img, block_size, transform_function):\n",
    "    '''\n",
    "    Apply block-wise DCT or IDCT to an image.\n",
    "    '''\n",
    "    size = img.shape\n",
    "    transformed_img = np.zeros(size, dtype=float)\n",
    "\n",
    "    for y in range(0, size[0], block_size):\n",
    "        for x in range(0, size[1], block_size):\n",
    "            block = img[y:y+block_size, x:x+block_size]\n",
    "            transformed_img[y:y+block_size, x:x+block_size] = transform_function(block)\n",
    "\n",
    "    return transformed_img\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idct_manual_2d(dct_matrix):\n",
    "    N, M = dct_matrix.shape\n",
    "    reconstructed_matrix = np.zeros((N, M))\n",
    "    for n1 in range(N):\n",
    "        for n2 in range(M):\n",
    "            sum_value = 0\n",
    "            for k1 in range(N):\n",
    "                for k2 in range(M):\n",
    "                    sum_value += dct_matrix[k1, k2] * \\\n",
    "                                 np.cos(np.pi * k1 * (2 * n1 + 1) / (2 * N)) * \\\n",
    "                                 np.cos(np.pi * k2 * (2 * n2 + 1) / (2 * M))\n",
    "            reconstructed_matrix[n1, n2] = sum_value / (N * M)  # Normalização\n",
    "    return reconstructed_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import idct\n",
    "inversa_usando_scipy=idct(usando_scipy, type=2, norm='ortho')\n",
    "plotImage(inversa_usando_scipy,'IDCT SCIPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inversa_manual=idct_manual_2d(dct_manual)\n",
    "plotImage(inversa_manual,'DCT manual')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificar/Decodidicar (huffman) - Araju\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, freq, symbol=None, left=None, right=None):\n",
    "        self.freq = freq\n",
    "        self.symbol = symbol\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq\n",
    "\n",
    "def build_huffman_tree(frequencies):\n",
    "    heap = [Node(freq, symbol) for symbol, freq in frequencies.items()]\n",
    "    heapq.heapify(heap)\n",
    "\n",
    "    while len(heap) > 1:\n",
    "        left = heapq.heappop(heap)\n",
    "        right = heapq.heappop(heap)\n",
    "        merged = Node(left.freq + right.freq, left=left, right=right)\n",
    "        heapq.heappush(heap, merged)\n",
    "\n",
    "    return heap[0] if heap else None\n",
    "\n",
    "def generate_huffman_codes(node, prefix=\"\", codebook=None):\n",
    "    if codebook is None:\n",
    "        codebook = {}\n",
    "\n",
    "    if node is not None:\n",
    "        if node.symbol is not None:\n",
    "            codebook[node.symbol] = prefix\n",
    "        generate_huffman_codes(node.left, prefix + \"0\", codebook)\n",
    "        generate_huffman_codes(node.right, prefix + \"1\", codebook)\n",
    "\n",
    "    return codebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvar no arquivo a imagem comprimida/ descomprimir a imagem -  Araju\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data, huffman_codes):\n",
    "    return ''.join(huffman_codes[symbol] for symbol in data)\n",
    "\n",
    "def decode_data(encoded_data, huffman_codes):\n",
    "    reverse_huffman_codes = {v: k for k, v in huffman_codes.items()}\n",
    "    current_code = \"\"\n",
    "    decoded_data = []\n",
    "\n",
    "    for bit in encoded_data:\n",
    "        current_code += bit\n",
    "        if current_code in reverse_huffman_codes:\n",
    "            decoded_data.append(reverse_huffman_codes[current_code])\n",
    "            current_code = \"\"\n",
    "\n",
    "    return decoded_data\n",
    "\n",
    "\n",
    "def save_to_file(original_image_shape, filename, huffman_codes, encoded_data):\n",
    "    with open(filename, 'wb') as file:\n",
    "        file.write(struct.pack('<I', original_image_shape[0]))\n",
    "        file.write(struct.pack('<I', original_image_shape[1]))\n",
    "        # Save the number of unique symbols\n",
    "        file.write(struct.pack('<I', len(huffman_codes)))\n",
    "\n",
    "        # Save the Huffman codes\n",
    "        for symbol, code in huffman_codes.items():\n",
    "            file.write(struct.pack('<i', symbol))  # Symbol as 4 bytes\n",
    "            file.write(struct.pack('<B', len(code)))  # Length of the code\n",
    "            file.write(code.encode())  # Code as bytes\n",
    "\n",
    "        # Save the length of the encoded data in bits\n",
    "        file.write(struct.pack('<I', len(encoded_data)))\n",
    "\n",
    "        # Convert the encoded data to bytes\n",
    "        buffer = 0\n",
    "        buffer_length = 0\n",
    "        byte_array = bytearray()\n",
    "\n",
    "        for bit in encoded_data:\n",
    "            buffer = (buffer << 1) | int(bit)\n",
    "            buffer_length += 1\n",
    "\n",
    "            if buffer_length == 8:\n",
    "                byte_array.append(buffer)\n",
    "                buffer = 0\n",
    "                buffer_length = 0\n",
    "\n",
    "        if buffer_length > 0:\n",
    "            buffer <<= (8 - buffer_length)\n",
    "            byte_array.append(buffer)\n",
    "        print(sys.getsizeof(byte_array))\n",
    "        file.write(byte_array)\n",
    "\n",
    "def load_from_file(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        # Read the shape of the original image\n",
    "        original_image_shape = (struct.unpack('<I', file.read(4))[0], struct.unpack('<I', file.read(4))[0])\n",
    "        # Read the number of unique symbols\n",
    "        num_symbols = struct.unpack('<I', file.read(4))[0]\n",
    "\n",
    "        # Read the Huffman codes\n",
    "        huffman_codes = {}\n",
    "        for _ in range(num_symbols):\n",
    "            symbol = struct.unpack('<i', file.read(4))[0]\n",
    "            code_length = struct.unpack('<B', file.read(1))[0]\n",
    "            code = file.read(code_length).decode()\n",
    "            huffman_codes[symbol] = code\n",
    "\n",
    "        # Read the length of the encoded data in bits\n",
    "        encoded_data_length = struct.unpack('<I', file.read(4))[0]\n",
    "\n",
    "        # Read the encoded data as bits\n",
    "        encoded_data = ''\n",
    "        while len(encoded_data) < encoded_data_length:\n",
    "            byte = file.read(1)\n",
    "            if not byte:\n",
    "                break\n",
    "            byte_value = ord(byte)\n",
    "            encoded_data += f'{byte_value:08b}'\n",
    "\n",
    "        return original_image_shape, huffman_codes, encoded_data[:encoded_data_length]\n",
    "\n",
    "def huffman_encode_matrix(matrix):\n",
    "    flat_list = [item for sublist in matrix for item in sublist]\n",
    "    frequencies = Counter(flat_list)\n",
    "    huffman_tree = build_huffman_tree(frequencies)\n",
    "    huffman_codes = generate_huffman_codes(huffman_tree)\n",
    "    encoded_data = encode_data(flat_list, huffman_codes)\n",
    "    return huffman_codes, encoded_data\n",
    "\n",
    "def huffman_decode_matrix(encoded_data, huffman_codes, original_shape):\n",
    "    decoded_flat_list = decode_data(encoded_data, huffman_codes)\n",
    "    matrix = []\n",
    "    index = 0\n",
    "    for row_size in original_shape:\n",
    "        matrix.append(decoded_flat_list[index:index + row_size])\n",
    "        index += row_size\n",
    "    return matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Matrix 8 x 8\n",
    "matrix = [[1, 2, 3, 4, 5, 6, 7, 8],\n",
    "          [2, 2, 2, 2, 2, 2, 2, 2],\n",
    "          [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "          [4, 4, 4, 4, 4, 4, 4, 4],\n",
    "          [5, 6, 7, 8, 9, 10, 11, 12],\n",
    "          [6, 6, 6, 6, 6, 6, 6, 6],\n",
    "          [7, 8, 9, 10, 11, 12, 13, 14],\n",
    "          [8, 8, 8, 8, 8, 8, 8, 8]]\n",
    "matrix = np.array(matrix)\n",
    "original_shape = [len(row) for row in matrix]\n",
    "huffman_codes, encoded_data = huffman_encode_matrix(matrix)\n",
    "filename = 'matrix.huff'\n",
    "save_to_file(matrix.shape, filename, huffman_codes, encoded_data)\n",
    "\n",
    "\n",
    "loaded_orginal_image_shape, loaded_huffman_codes, loaded_encoded_data = load_from_file(filename)\n",
    "decoded_matrix = huffman_decode_matrix(loaded_encoded_data, loaded_huffman_codes, original_shape)\n",
    "print(matrix.shape == np.array(decoded_matrix).shape)\n",
    "print(decoded_matrix == matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
