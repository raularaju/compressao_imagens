{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import heapq\n",
    "from collections import defaultdict, Counter\n",
    "import struct\n",
    "import sys\n",
    "from scipy.fftpack import dct, idct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções úteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEntropy(image):\n",
    "    hist = cv2.calcHist([image],[0],None,[256],[0,256])\n",
    "    hist = hist.ravel()/hist.sum()\n",
    "    logs = np.log2(hist+0.00001)\n",
    "    entropy = -1 * (hist*logs).sum()\n",
    "    return entropy\n",
    "\n",
    "def divideImageIntoSubImages(image, subImageSize):\n",
    "    subImages = []\n",
    "    for i in range(0, image.shape[0], subImageSize):\n",
    "        for j in range(0, image.shape[1], subImageSize):\n",
    "            subImages.append(image[i:i+subImageSize, j:j+subImageSize])\n",
    "    return np.array(subImages)\n",
    "\n",
    "def reconstructImage(subimages, originalImageShape):\n",
    "    image = np.zeros(originalImageShape)\n",
    "    idx = 0\n",
    "    for i in range(0, originalImageShape[0], subimages[0].shape[0]):\n",
    "        for j in range(0, originalImageShape[1], subimages[0].shape[1]):\n",
    "            image[i:i+subimages[0].shape[0], j:j+subimages[0].shape[1]] = subimages[idx]\n",
    "            idx += 1\n",
    "    return image\n",
    "\n",
    "def getNumberOfDifferentColors(img):\n",
    "    return len(np.unique(img))\n",
    "\n",
    "def plotImage(img, title):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_IMAGE = cv2.imread('./imagens/unequal.pgm',0)\n",
    "ORIGINAL_IMAGE_SHAPE = ORIGINAL_IMAGE.shape\n",
    "plotImage(ORIGINAL_IMAGE, 'Imagem Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBIMAGES = divideImageIntoSubImages(ORIGINAL_IMAGE, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tirar os residuos/  Pegar os resíduos e transformar na imagem original - Giovana "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_left_column(macroblock):\n",
    "    \"\"\"\n",
    "    Retrieves the last column of the given macroblock.\n",
    "    \"\"\"\n",
    "    if macroblock is not None and macroblock.shape[1] > 0:\n",
    "        return macroblock[:, -1]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_top_row(macroblock):\n",
    "    \"\"\"\n",
    "    Retrieves the first row of the given macroblock.\n",
    "    \"\"\"\n",
    "    if macroblock is not None and macroblock.shape[0] > 0:\n",
    "        return macroblock[0, :]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    \n",
    "def generate_macroblocks(img, block_size):\n",
    "    \"\"\"\n",
    "    Generates macroblocks of a given size from the image.\n",
    "    \"\"\"\n",
    "    for y in range(0, img.shape[0], block_size):\n",
    "        for x in range(0, img.shape[1], block_size):\n",
    "            macroblock = img[y:y+block_size, x:x+block_size]\n",
    "            yield y, x, macroblock\n",
    "\n",
    "def apply_horizontal_predictive(macroblock,left_column = None):\n",
    "    \"\"\"\n",
    "    Applies a predictive function without loss on each macro block based on\n",
    "    the formula f(x, y) = f(x, y) - f(x, y - 1).\n",
    "    \"\"\"\n",
    "    new_block = np.zeros_like(macroblock, dtype=float)\n",
    "\n",
    "    for i in range(macroblock.shape[0]):\n",
    "        if left_column is not None:\n",
    "            new_block[i, 0] = macroblock[i, 0] - left_column[i]\n",
    "        else:\n",
    "            new_block[i, 0] = macroblock[i, 0]\n",
    "\n",
    "    for i in range(macroblock.shape[0]):\n",
    "        for j in range(1, macroblock.shape[1]):\n",
    "            new_block[i, j] = macroblock[i, j] - macroblock[i, j-1]\n",
    "    return new_block\n",
    "\n",
    "def apply_vertical_predictive(macroblock, top_row=None):\n",
    "    \"\"\"\n",
    "    Applies a vertical predictive function on a given macroblock based on the formula\n",
    "    f(x, y) = f(x, y) - f(x-1, y). \n",
    "    \"\"\"\n",
    "    new_block = np.zeros_like(macroblock, dtype=float)\n",
    "    \n",
    "    # Apply prediction for each element in the macroblock\n",
    "    for j in range(macroblock.shape[1]):\n",
    "        # Use top_row if available for the first row\n",
    "        if top_row is not None:\n",
    "            new_block[0, j] = macroblock[0, j] - top_row[j]\n",
    "        else:\n",
    "            new_block[0, j] = macroblock[0, j]  # Keep the real value if no top row\n",
    "        \n",
    "    for i in range(1,macroblock.shape[0]):\n",
    "        for j in range(macroblock.shape[1]):\n",
    "            new_block[i, j] = macroblock[i, j] - macroblock[i-1, j]\n",
    "    \n",
    "    return new_block\n",
    "\n",
    "\n",
    "def process_image(img, block_size):\n",
    "    \"\"\"\n",
    "    Processes the entire image by dividing it into macroblocks,\n",
    "    applying the predictive function to each block, and \n",
    "    reconstructing the output image.\n",
    "    \"\"\"\n",
    "    pred_img = np.zeros_like(img, dtype=float)\n",
    "    last_macroblock = None\n",
    "    \n",
    "    for y, x, macroblock in generate_macroblocks(img, block_size):\n",
    "        left_column = get_left_column(last_macroblock)\n",
    "        top_row = get_top_row(last_macroblock)\n",
    "        # new_block = apply_horizontal_predictive(left_column,macroblock.astype(float))\n",
    "        new_block = apply_vertical_predictive(macroblock.astype(float),top_row)\n",
    "\n",
    "        pred_img[y:y+block_size, x:x+block_size] = new_block\n",
    "\n",
    "        last_macroblock = macroblock\n",
    "\n",
    "\n",
    "    return pred_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazer a tranformada/fazer a transformada inversa - Fernando\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dct_2d_manual(matrix):\n",
    " \n",
    "    N, M = matrix.shape\n",
    "    dct_result = np.zeros((N, M))\n",
    "    print(N,M)\n",
    "    for k1 in range(N):\n",
    "        for k2 in range(M):\n",
    "            sum_value = 0\n",
    "            for n1 in range(N):\n",
    "                for n2 in range(M):\n",
    "                    sum_value += matrix[n1, n2] * np.cos((np.pi/N)*(n1+0.5)*k1)*np.cos((np.pi/M)*(n2+0.5)*k2)\n",
    "\n",
    "            dct_result[k1, k2] = sum_value\n",
    "    \n",
    "    return dct_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import dct\n",
    "usando_scipy=dct(ORIGINAL_IMAGE, type=2, norm='ortho')\n",
    "plotImage(usando_scipy,'DCT SCIPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_manual = dct_2d_manual(ORIGINAL_IMAGE)\n",
    "plotImage(dct_manual,'DCT manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dct(img):\n",
    "    ''' \n",
    "    Get 2D Cosine Transform of Image\n",
    "    '''\n",
    "    return fftpack.dct(fftpack.dct(img.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "def get_idct(coefficients):\n",
    "    ''' \n",
    "    Get 2D Inverse Cosine Transform of Image\n",
    "    '''\n",
    "    return fftpack.idct(fftpack.idct(coefficients.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "def apply_image_transform(img, block_size, transform_function):\n",
    "    '''\n",
    "    Apply block-wise DCT or IDCT to an image.\n",
    "    '''\n",
    "    size = img.shape\n",
    "    transformed_img = np.zeros(size, dtype=float)\n",
    "\n",
    "    for y in range(0, size[0], block_size):\n",
    "        for x in range(0, size[1], block_size):\n",
    "            block = img[y:y+block_size, x:x+block_size]\n",
    "            transformed_img[y:y+block_size, x:x+block_size] = transform_function(block)\n",
    "\n",
    "    return transformed_img\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idct_manual_2d(dct_matrix):\n",
    "    N, M = dct_matrix.shape\n",
    "    reconstructed_matrix = np.zeros((N, M))\n",
    "    for n1 in range(N):\n",
    "        for n2 in range(M):\n",
    "            sum_value = 0\n",
    "            for k1 in range(N):\n",
    "                for k2 in range(M):\n",
    "                    sum_value += dct_matrix[k1, k2] * \\\n",
    "                                 np.cos(np.pi * k1 * (2 * n1 + 1) / (2 * N)) * \\\n",
    "                                 np.cos(np.pi * k2 * (2 * n2 + 1) / (2 * M))\n",
    "            reconstructed_matrix[n1, n2] = sum_value / (N * M)  # Normalização\n",
    "    return reconstructed_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import idct\n",
    "inversa_usando_scipy=idct(usando_scipy, type=2, norm='ortho')\n",
    "plotImage(inversa_usando_scipy,'IDCT SCIPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inversa_manual=idct_manual_2d(dct_manual)\n",
    "plotImage(inversa_manual,'DCT manual')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificar/Decodidicar (huffman) - Araju\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, freq, symbol=None, left=None, right=None):\n",
    "        self.freq = freq\n",
    "        self.symbol = symbol\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq\n",
    "\n",
    "def build_huffman_tree(frequencies):\n",
    "    heap = [Node(freq, symbol) for symbol, freq in frequencies.items()]\n",
    "    heapq.heapify(heap)\n",
    "\n",
    "    while len(heap) > 1:\n",
    "        left = heapq.heappop(heap)\n",
    "        right = heapq.heappop(heap)\n",
    "        merged = Node(left.freq + right.freq, left=left, right=right)\n",
    "        heapq.heappush(heap, merged)\n",
    "\n",
    "    return heap[0] if heap else None\n",
    "\n",
    "def generate_huffman_codes(node, prefix=\"\", codebook=None):\n",
    "    if codebook is None:\n",
    "        codebook = {}\n",
    "\n",
    "    if node is not None:\n",
    "        if node.symbol is not None:\n",
    "            codebook[node.symbol] = prefix\n",
    "        generate_huffman_codes(node.left, prefix + \"0\", codebook)\n",
    "        generate_huffman_codes(node.right, prefix + \"1\", codebook)\n",
    "\n",
    "    return codebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvar no arquivo a imagem comprimida/ descomprimir a imagem -  Araju\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data, huffman_codes):\n",
    "    return ''.join(huffman_codes[symbol] for symbol in data)\n",
    "\n",
    "def decode_data(encoded_data, huffman_codes):\n",
    "    reverse_huffman_codes = {v: k for k, v in huffman_codes.items()}\n",
    "    current_code = \"\"\n",
    "    decoded_data = []\n",
    "\n",
    "    for bit in encoded_data:\n",
    "        current_code += bit\n",
    "        if current_code in reverse_huffman_codes:\n",
    "            decoded_data.append(reverse_huffman_codes[current_code])\n",
    "            current_code = \"\"\n",
    "\n",
    "    return decoded_data\n",
    "\n",
    "\n",
    "def save_to_file(original_image_shape, filename, huffman_codes, encoded_data):\n",
    "    with open(filename, 'wb') as file:\n",
    "        file.write(struct.pack('<I', original_image_shape[0]))\n",
    "        file.write(struct.pack('<I', original_image_shape[1]))\n",
    "        # Save the number of unique symbols\n",
    "        file.write(struct.pack('<I', len(huffman_codes)))\n",
    "\n",
    "        # Save the Huffman codes\n",
    "        for symbol, code in huffman_codes.items():\n",
    "            file.write(struct.pack('<i', symbol))  # Symbol as 4 bytes\n",
    "            file.write(struct.pack('<B', len(code)))  # Length of the code\n",
    "            file.write(code.encode())  # Code as bytes\n",
    "\n",
    "        # Save the length of the encoded data in bits\n",
    "        file.write(struct.pack('<I', len(encoded_data)))\n",
    "\n",
    "        # Convert the encoded data to bytes\n",
    "        buffer = 0\n",
    "        buffer_length = 0\n",
    "        byte_array = bytearray()\n",
    "\n",
    "        for bit in encoded_data:\n",
    "            buffer = (buffer << 1) | int(bit)\n",
    "            buffer_length += 1\n",
    "\n",
    "            if buffer_length == 8:\n",
    "                byte_array.append(buffer)\n",
    "                buffer = 0\n",
    "                buffer_length = 0\n",
    "\n",
    "        if buffer_length > 0:\n",
    "            buffer <<= (8 - buffer_length)\n",
    "            byte_array.append(buffer)\n",
    "        print(sys.getsizeof(byte_array))\n",
    "        file.write(byte_array)\n",
    "\n",
    "def load_from_file(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        # Read the shape of the original image\n",
    "        original_image_shape = (struct.unpack('<I', file.read(4))[0], struct.unpack('<I', file.read(4))[0])\n",
    "        # Read the number of unique symbols\n",
    "        num_symbols = struct.unpack('<I', file.read(4))[0]\n",
    "\n",
    "        # Read the Huffman codes\n",
    "        huffman_codes = {}\n",
    "        for _ in range(num_symbols):\n",
    "            symbol = struct.unpack('<i', file.read(4))[0]\n",
    "            code_length = struct.unpack('<B', file.read(1))[0]\n",
    "            code = file.read(code_length).decode()\n",
    "            huffman_codes[symbol] = code\n",
    "\n",
    "        # Read the length of the encoded data in bits\n",
    "        encoded_data_length = struct.unpack('<I', file.read(4))[0]\n",
    "\n",
    "        # Read the encoded data as bits\n",
    "        encoded_data = ''\n",
    "        while len(encoded_data) < encoded_data_length:\n",
    "            byte = file.read(1)\n",
    "            if not byte:\n",
    "                break\n",
    "            byte_value = ord(byte)\n",
    "            encoded_data += f'{byte_value:08b}'\n",
    "\n",
    "        return original_image_shape, huffman_codes, encoded_data[:encoded_data_length]\n",
    "\n",
    "def huffman_encode_matrix(matrix):\n",
    "    flat_list = [item for sublist in matrix for item in sublist]\n",
    "    frequencies = Counter(flat_list)\n",
    "    huffman_tree = build_huffman_tree(frequencies)\n",
    "    huffman_codes = generate_huffman_codes(huffman_tree)\n",
    "    encoded_data = encode_data(flat_list, huffman_codes)\n",
    "    return huffman_codes, encoded_data\n",
    "\n",
    "def huffman_decode_matrix(encoded_data, huffman_codes, original_shape):\n",
    "    decoded_flat_list = decode_data(encoded_data, huffman_codes)\n",
    "    matrix = []\n",
    "    index = 0\n",
    "    for row_size in original_shape:\n",
    "        matrix.append(decoded_flat_list[index:index + row_size])\n",
    "        index += row_size\n",
    "    return matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Matrix 8 x 8\n",
    "matrix = [[1, 2, 3, 4, 5, 6, 7, 8],\n",
    "          [2, 2, 2, 2, 2, 2, 2, 2],\n",
    "          [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "          [4, 4, 4, 4, 4, 4, 4, 4],\n",
    "          [5, 6, 7, 8, 9, 10, 11, 12],\n",
    "          [6, 6, 6, 6, 6, 6, 6, 6],\n",
    "          [7, 8, 9, 10, 11, 12, 13, 14],\n",
    "          [8, 8, 8, 8, 8, 8, 8, 8]]\n",
    "matrix = np.array(matrix)\n",
    "original_shape = [len(row) for row in matrix]\n",
    "huffman_codes, encoded_data = huffman_encode_matrix(matrix)\n",
    "filename = 'matrix.huff'\n",
    "save_to_file(matrix.shape, filename, huffman_codes, encoded_data)\n",
    "\n",
    "\n",
    "loaded_orginal_image_shape, loaded_huffman_codes, loaded_encoded_data = load_from_file(filename)\n",
    "decoded_matrix = huffman_decode_matrix(loaded_encoded_data, loaded_huffman_codes, original_shape)\n",
    "print(matrix.shape == np.array(decoded_matrix).shape)\n",
    "print(decoded_matrix == matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
