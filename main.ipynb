{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import heapq\n",
    "from collections import defaultdict, Counter\n",
    "import struct\n",
    "import sys\n",
    "from scipy import fftpack\n",
    "from bitarray import bitarray\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções úteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def calcEntropy(image):\n",
    "    hist = cv2.calcHist([image],[0],None,[256],[0,256])\n",
    "    hist = hist.ravel()/hist.sum()\n",
    "    print(\"prob \", hist)\n",
    "    logs = np.log2(hist+0.00001)\n",
    "    entropy = -1 * (hist*logs).sum()\n",
    "    return entropy\n",
    " \"\"\"\n",
    "def calculate_entropy(matrix):\n",
    "    number_of_elements = matrix.shape[0] * matrix.shape[1]\n",
    "    occurence_dict = dict(Counter(matrix.flatten()))\n",
    "    entropy = 0\n",
    "    for key in occurence_dict:\n",
    "        probability = occurence_dict[key] / number_of_elements\n",
    "        entropy -= probability * np.log2(probability)\n",
    "    return entropy\n",
    "\n",
    "def plot_histogram(matrix):\n",
    "    # Flatten the matrix to a 1D array\n",
    "    flattened_matrix = matrix.flatten()\n",
    "    \n",
    "    # Plot the histogram\n",
    "    plt.hist(flattened_matrix, bins=range(int(flattened_matrix.min()), int(flattened_matrix.max()) + 2), edgecolor='black', align='left')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Value Occurrences in Matrix')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\"\"\" def divideImageIntoSubImages(image, subImageSize):\n",
    "    subImages = []\n",
    "    for i in range(0, image.shape[0], subImageSize):\n",
    "        for j in range(0, image.shape[1], subImageSize):\n",
    "            subImages.append(image[i:i+subImageSize, j:j+subImageSize])\n",
    "    return np.array(subImages)\n",
    "\n",
    "def reconstructImage(subimages, originalImageShape):\n",
    "    image = np.zeros(originalImageShape)\n",
    "    idx = 0\n",
    "    for i in range(0, originalImageShape[0], subimages[0].shape[0]):\n",
    "        for j in range(0, originalImageShape[1], subimages[0].shape[1]):\n",
    "            image[i:i+subimages[0].shape[0], j:j+subimages[0].shape[1]] = subimages[idx]\n",
    "            idx += 1\n",
    "    return image \"\"\"\n",
    "\n",
    "def get_number_of_different_colors(img):\n",
    "    return len(np.unique(img))\n",
    "\n",
    "def plot_image(img, title):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def add_padding(img, block_size):\n",
    "    rows, cols = img.shape\n",
    "    paddedImg = np.zeros((rows + block_size - rows % block_size, cols + block_size - cols % block_size))\n",
    "    paddedImg[:rows, :cols] = img\n",
    "    return paddedImg\n",
    "\n",
    "def remove_padding(img, original_shape):\n",
    "    return img[:original_shape[0], :original_shape[1]]\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "\n",
    "def psnr(predictions, targets):\n",
    "    rmsev = rmse(predictions, targets)\n",
    "    return 20 * np.log10(255/rmsev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura da Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME = 'baboon'\n",
    "ORIGINAL_IMAGE = cv2.imread(f'./imagens/{IMAGE_NAME}.pgm',0)\n",
    "ORIGINAL_IMAGE_SHAPE = ORIGINAL_IMAGE.shape\n",
    "plot_image(ORIGINAL_IMAGE, 'Imagem Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDED_IMAGE = add_padding(ORIGINAL_IMAGE, 8)\n",
    "plot_image(PADDED_IMAGE, 'Imagem com padding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ORIGINAL_IMAGE[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ORIGINAL_IMAGE# np.array([[1,2,3],[4,5,6],[7,8,9]]).astype(np.uint8)\n",
    "print(calculate_entropy(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tirar os residuos/  Pegar os resíduos e transformar na imagem original - Giovana "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_macroblocks(img, block_size):\n",
    "    \"\"\"\n",
    "    Generates macroblocks of a given size from the image.\n",
    "    \"\"\"\n",
    "    for y in range(0, img.shape[0], block_size):\n",
    "        for x in range(0, img.shape[1], block_size):\n",
    "            macroblock = img[y:y+block_size, x:x+block_size]\n",
    "            yield y, x, macroblock\n",
    "\n",
    "def get_vertical_prediction(macroblock,left_column = None):\n",
    "    \"\"\"\n",
    "    Applies a predictive function without loss on each macro block based on\n",
    "    the formula f(x, y) = f(x, y) - f(x, y - 1).\n",
    "    \"\"\"\n",
    "    new_block = np.zeros_like(macroblock, dtype=float)\n",
    "    if left_column is not None:\n",
    "        new_block[:,:] = left_column\n",
    "    else: \n",
    "        new_block[:,0] = 0\n",
    "        new_block[:,1:] = macroblock[:,0].reshape(-1, 1) \n",
    "    # print(new_block,left_column)\n",
    "    # new_block[:,:] = macroblock[:,0:]\n",
    "    return new_block\n",
    "\n",
    "def get_horizontal_prediction(macroblock, top_row=None):\n",
    "    \"\"\"\n",
    "    Applies a vertical predictive function on a given macroblock based on the formula\n",
    "    f(x, y) = f(x, y) - f(x-1, y). \n",
    "    \"\"\"\n",
    "    new_block = np.zeros_like(macroblock, dtype=float)\n",
    "    if top_row is not None:\n",
    "        new_block[:,:] = top_row.reshape(-1, 1) \n",
    "    else: \n",
    "        new_block[0,:] = 0\n",
    "        new_block[1:,:] = macroblock[0,:].reshape(1, -1) \n",
    "    \n",
    "    # new_block[1:,:] = macroblock[0:-1,:]\n",
    "    \n",
    "    return new_block\n",
    "\n",
    "def get_mean_prediction(macroblock,left_column,top_row):\n",
    "\n",
    "    block_size = macroblock.shape[0]\n",
    "    new_block = np.zeros_like(macroblock, dtype=float)\n",
    "\n",
    "    if left_column is not None and top_row is not None:\n",
    "        mean_value = int((np.sum(top_row) + np.sum(left_column)) / (2 * block_size))\n",
    "        new_block = np.full((block_size, block_size), mean_value)\n",
    "\n",
    "    return new_block\n",
    "\n",
    "def calculate_entropy(block):\n",
    "    \"\"\"\n",
    "    Calculates the entropy of the given block.\n",
    "    \"\"\"\n",
    "    # Flatten the block and calculate the probability distribution\n",
    "    if(type(block) == list):\n",
    "        flattened_block = sum(block, [])\n",
    "    else:\n",
    "        flattened_block = block.flatten()\n",
    "    value_counts = Counter(flattened_block)\n",
    "    \n",
    "    # Calculate the probabilities of each unique value\n",
    "    total_count = sum(value_counts.values())\n",
    "    probabilities = np.array([count / total_count for count in value_counts.values()])\n",
    "    \n",
    "    # Calculate entropy\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "def get_best_prediction(original_block,block_vertical, block_horizontal,block_mean):\n",
    "    \"\"\"\n",
    "    Compares two blocks by calculating their entropy and returns the block\n",
    "    with the lowest entropy along with an indicator of which block was chosen.\n",
    "    \"\"\"\n",
    "    # Calculate entropy for both blocks\n",
    "    entropy_vertical = calculate_entropy(block_vertical)\n",
    "    entropy_horizontal = calculate_entropy(block_horizontal)\n",
    "    entropy_mean = calculate_entropy(block_mean)\n",
    "    \n",
    "    # Find the block with the minimum entropy\n",
    "    entropies = [entropy_vertical, entropy_horizontal, entropy_mean]\n",
    "    blocks = [block_vertical, block_horizontal, block_mean]\n",
    "    min_entropy_index = entropies.index(min(entropies))\n",
    "    \n",
    "    # Return the block with the lowest entropy and its index\n",
    "    return blocks[min_entropy_index],min_entropy_index\n",
    "    \n",
    "def process_image(img, block_size):\n",
    "    \"\"\"\n",
    "    Processes the entire image by dividing it into macroblocks,\n",
    "    applying the predictive function to each block, and \n",
    "    reconstructing the output image.\n",
    "    \"\"\"\n",
    "    options = []  # To store the choice of predictive function (0 or 1)\n",
    "    pred_img = np.zeros_like(img, dtype=float)\n",
    "    \n",
    "    # Iterate over each macroblock in the image\n",
    "    for y, x, macroblock in generate_macroblocks(img, block_size):\n",
    "        # Get left column and top row from the last macroblock for prediction\n",
    "        left_column = img[y:y+block_size,x-1] if (x > 0) else None\n",
    "        top_row = img[y-1, x:x+block_size] if (y > 0) else None\n",
    "\n",
    "        block_vertical   = macroblock - get_vertical_prediction(macroblock,left_column) \n",
    "        block_horizontal = macroblock - get_horizontal_prediction(macroblock,top_row)\n",
    "        block_mean = macroblock - get_mean_prediction(macroblock,left_column,top_row)\n",
    "\n",
    "\n",
    "\n",
    "        # Select the best prediction based on entropy\n",
    "        new_block, option = get_best_prediction(macroblock,block_vertical, block_horizontal,block_mean) ## testar remover e calcular a entropia\n",
    "        options.append(option)\n",
    "\n",
    "        # Place the processed block back into the image\n",
    "        pred_img[y:y+block_size, x:x+block_size] = new_block\n",
    "\n",
    "    return pred_img, options\n",
    "\n",
    "def reconstruct_image(residual_img, block_size, pred_type):\n",
    "    \"\"\"\n",
    "    Reconstructs the original image from a residual image.\n",
    "    \"\"\"\n",
    "    # Create an empty array to store the reconstructed original image\n",
    "    original_img = np.zeros_like(residual_img, dtype=float)\n",
    "\n",
    "    i = 0\n",
    "    # Iterate over the image in blocks of size `block_size`\n",
    "    for y, x, residual_block in generate_macroblocks(residual_img, block_size):\n",
    "        left_column = original_img[y:y+block_size,x-1] if (x > 0) else None\n",
    "        top_row = original_img[y-1, x:x+block_size] if (y > 0) else None\n",
    "\n",
    "        reconstructed_block = np.zeros_like(residual_block, dtype=float)\n",
    "        \n",
    "        # Extract the current residual block\n",
    "        if pred_type[i] == 0:\n",
    "            reconstructed_block = get_vertical_prediction(residual_block, left_column)\n",
    "            \n",
    "        \n",
    "        elif pred_type[i] == 1:\n",
    "            reconstructed_block = get_horizontal_prediction(residual_block, top_row)\n",
    "\n",
    "        elif pred_type[i] == 2:\n",
    "            reconstructed_block = get_mean_prediction(residual_block,left_column, top_row)\n",
    "        \n",
    "        # Place the reconstructed block back into the image\n",
    "        original_img[y:y+block_size, x:x+block_size] = reconstructed_block + residual_block\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    return original_img\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zig Zag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYMBOL_EOB = 2**15 - 1\n",
    "print(SYMBOL_EOB)\n",
    "def zigzag_encode(matrix):\n",
    "    \"\"\"\n",
    "    Encodes a 2D matrix into a 1D array using zig-zag traversal.\n",
    "    \"\"\"\n",
    "    rows, cols = matrix.shape\n",
    "    result = []\n",
    "    for s in range(rows + cols - 1):\n",
    "        if s % 2 == 0:  # Even diagonals go \"up\"\n",
    "            for i in range(s + 1):\n",
    "                j = s - i\n",
    "                if i < rows and j < cols:\n",
    "                    result.append(matrix[i, j])\n",
    "        else:  # Odd diagonals go \"down\"\n",
    "            for i in range(s + 1):\n",
    "                j = s - i\n",
    "                if j < rows and i < cols:\n",
    "                    result.append(matrix[j, i])\n",
    "    return result\n",
    "\n",
    "def zigzag_decode(encoded, block_size):\n",
    "    \"\"\"\n",
    "    Decodes a 1D array into a 2D matrix using zig-zag traversal.\n",
    "    \"\"\"\n",
    "    rows,cols = block_size,block_size\n",
    "    matrix = np.zeros((rows, cols), dtype=int)\n",
    "    index = 0\n",
    "    for s in range(rows + cols - 1):\n",
    "        if s % 2 == 0:  # Even diagonals go \"up\"\n",
    "            for i in range(s + 1):\n",
    "                j = s - i\n",
    "                if i < rows and j < cols:\n",
    "                    matrix[i, j] = encoded[index]\n",
    "                    index += 1\n",
    "        else:  # Odd diagonals go \"down\"\n",
    "            for i in range(s + 1):\n",
    "                j = s - i\n",
    "                if j < rows and i < cols:\n",
    "                    matrix[j, i] = encoded[index]\n",
    "                    index += 1\n",
    "    return matrix\n",
    "\n",
    "def apply_zigzag_image(image, block_size):\n",
    "\n",
    "    zigzag_code = []\n",
    "\n",
    "    for _, _, residual_block in generate_macroblocks(image, block_size):\n",
    "        zigzag_code.append(zigzag_encode(residual_block))\n",
    "    \n",
    "    return np.array(zigzag_code)\n",
    "\n",
    "def apply_zigzag_decode(zigzags, block_size, image_shape):\n",
    "    decoded = np.zeros(image_shape)\n",
    "    index_zigzag = 0\n",
    "    for y, x, block in generate_macroblocks(decoded, block_size):\n",
    "        decoded[y:y+block_size, x:x+block_size] = zigzag_decode(zigzags[index_zigzag], block_size)\n",
    "        index_zigzag += 1\n",
    "    \n",
    "    return decoded\n",
    "\n",
    "def run_length_encode(data):\n",
    "    \"\"\"\n",
    "    Encodes a list using Run-Length Encoding (RLE).\n",
    "    \"\"\"\n",
    "\n",
    "    encoded = []\n",
    "    count = 1\n",
    "    for i in range(1, len(data)):\n",
    "        if data[i] == data[i - 1]:\n",
    "            count += 1\n",
    "        else:\n",
    "            encoded.append((data[i - 1], count))\n",
    "            count = 1\n",
    "    # Append the last element\n",
    "    encoded.append((data[-1], count))\n",
    "    return encoded\n",
    "\n",
    "def apply_run_length_zigzags(zigzags):\n",
    "    rle_code = []\n",
    "\n",
    "    for zigzag in zigzags:\n",
    "        rle_code.append(run_length_encode(zigzag))\n",
    "    return rle_code\n",
    "\n",
    "def run_length_decode(encoded):\n",
    "    \"\"\"\n",
    "    Decodes a Run-Length Encoded (RLE) list.\n",
    "    \"\"\"\n",
    "    decoded = []\n",
    "    for value, count in encoded:\n",
    "        decoded.extend([value] * count)\n",
    "    return decoded\n",
    "\n",
    "def zigzag_to_eob(zigzag_array):\n",
    "    rle = []\n",
    "    \n",
    "    # Iterate over the zigzag array\n",
    "    for i in range(len(zigzag_array)):\n",
    "        if zigzag_array[i] != 0:\n",
    "            rle.append(zigzag_array[i])\n",
    "        else:\n",
    "            # Check if all remaining zigzag_array[i]s are zero\n",
    "            if all(v == 0 for v in zigzag_array[i:]):\n",
    "                rle.append(SYMBOL_EOB)\n",
    "                break\n",
    "            else:\n",
    "                rle.append(0)        \n",
    "    return rle\n",
    "\n",
    "def eob_to_zigzag(eob_array):\n",
    "    zigzag = []\n",
    "    for i in range(len(eob_array)):\n",
    "        if eob_array[i] != SYMBOL_EOB:\n",
    "            zigzag.append(eob_array[i])\n",
    "        else:\n",
    "            zigzag.extend([0] * (BLOCK_SIZE * BLOCK_SIZE - i))\n",
    "            break\n",
    "    return zigzag\n",
    "\n",
    "def apply_zigzag_to_eob(image,block_size):\n",
    "    zigzag_code = []\n",
    "\n",
    "    for _, _, residual_block in generate_macroblocks(image, block_size):\n",
    "        zigzag_code.append(zigzag_to_eob(zigzag_encode(residual_block)))\n",
    "    \n",
    "    return zigzag_code\n",
    "\n",
    "def apply_eob_to_zigzag(zigzags):\n",
    "    zigzag_code = []\n",
    "    for zigzag in zigzags:\n",
    "        zigzag_code.append(eob_to_zigzag(zigzag))\n",
    "    \n",
    "    return np.array(zigzag_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazer a tranformada/fazer a transformada inversa - Fernando\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_matrix = np.matrix([[16, 11, 10, 16, 24, 40, 51, 61], \n",
    "                [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "                [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "                [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "                [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "                [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "                [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "                [72, 92, 95, 98, 112, 100, 103, 99]]) /10\n",
    "\n",
    "def get_dct(img):\n",
    "    ''' \n",
    "    Get 2D Cosine Transform of Image\n",
    "    '''\n",
    "    return fftpack.dct(fftpack.dct(img.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "def get_idct(coefficients):\n",
    "    ''' \n",
    "    Get 2D Inverse Cosine Transform of Image\n",
    "    '''\n",
    "    return fftpack.idct(fftpack.idct(coefficients.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "def apply_image_transformation(img, block_size, transform_function):\n",
    "    '''\n",
    "    Apply block-wise DCT or IDCT to an image.\n",
    "    '''\n",
    "    size = img.shape\n",
    "    transformed_img = np.zeros(size, dtype=float)\n",
    "\n",
    "    for y, x, macroblock in generate_macroblocks(img, block_size):\n",
    "        transformed_img[y:y+block_size, x:x+block_size] = transform_function(macroblock)\n",
    "        \n",
    "\n",
    "    return transformed_img\n",
    "\n",
    "def apply_quantization(transformed_image,block_size):\n",
    "\n",
    "    size = transformed_image.shape\n",
    "    quantized_image = np.zeros(size, dtype=float)\n",
    "    \n",
    "    for y, x, macroblock in generate_macroblocks(transformed_image, block_size):\n",
    "        quantized_block = np.divide(macroblock, quantization_matrix)\n",
    "        quantized_block = np.round(quantized_block)\n",
    "        quantized_image[y:y+block_size, x:x+block_size] = quantized_block\n",
    "    return quantized_image.astype(int)\n",
    "\n",
    "def apply_dequantization(transformed_image,block_size):\n",
    "\n",
    "    size = transformed_image.shape\n",
    "    dequantized_image = np.zeros(size, dtype=float)\n",
    "\n",
    "    for y, x, macroblock in generate_macroblocks(transformed_image, block_size):\n",
    "        dequantized_block = np.multiply(macroblock, quantization_matrix)\n",
    "        dequantized_image[y:y+block_size, x:x+block_size] = dequantized_block\n",
    "\n",
    "    return dequantized_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "img = ORIGINAL_IMAGE.astype(np.float64) - 128\n",
    "\n",
    "residuals, PREDICTIONS_OPTIONS = process_image(img, block_size)\n",
    "transformed_residuals = apply_image_transformation(residuals, block_size, get_dct)\n",
    "quantized_residuals = apply_quantization(transformed_residuals,block_size)\n",
    "zigzag_quantized_residuals = apply_zigzag_image(quantized_residuals,block_size)\n",
    "zigzag_quantized_residuals_with_eob = apply_zigzag_to_eob(quantized_residuals,block_size)\n",
    "print(quantized_residuals.shape)\n",
    "print(zigzag_quantized_residuals.shape)\n",
    "rle_encoded_residuals = apply_run_length_zigzags(zigzag_quantized_residuals)\n",
    "last_elements = zigzag_quantized_residuals[:, -1]\n",
    "\n",
    "# print(\"Last elements in each row:\", sum(last_elements))\n",
    "#print(zigzag_encoded_residuals_with_eob)\n",
    "# print(f\"Entropia sem rle e sem eob: {calculate_entropy(np.array(zigzag_encoded_residuals))}\")\n",
    "# print(f\"Entropia com eob: {calculate_entropy(zigzag_encoded_residuals_with_eob)}\")\n",
    "# print(f\"Entropia com rle: {calculate_entropy(rle_encoded_residuals)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_quantized_residuals = apply_zigzag_decode(zigzag_quantized_residuals, BLOCK_SIZE, ORIGINAL_IMAGE_SHAPE)\n",
    "print(_quantized_residuals.shape)\n",
    "_dequantized_residuals = apply_dequantization(_quantized_residuals,block_size)\n",
    "residuals_ = apply_image_transformation(_dequantized_residuals, block_size, get_idct)\n",
    "reconstructed_image = reconstruct_image(residuals_, block_size, PREDICTIONS_OPTIONS)\n",
    "reconstructed_image = reconstructed_image.astype(np.float64) + 128\n",
    "plot_image(reconstructed_image, 'Imagem Reconstruída')\n",
    "print(f\"RMSE : {rmse(reconstructed_image, ORIGINAL_IMAGE)}\")\n",
    "print(f\"PSNR : {psnr(reconstructed_image, ORIGINAL_IMAGE)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificar/Decodidicar (huffman) - Araju\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, freq, symbol=None, left=None, right=None):\n",
    "        self.freq = freq\n",
    "        self.symbol = symbol\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq\n",
    "\n",
    "def build_huffman_tree(frequencies):\n",
    "    heap = [Node(freq, symbol) for symbol, freq in frequencies.items()]\n",
    "    heapq.heapify(heap)\n",
    "\n",
    "    while len(heap) > 1:\n",
    "        left = heapq.heappop(heap)\n",
    "        right = heapq.heappop(heap)\n",
    "        merged = Node(left.freq + right.freq, left=left, right=right)\n",
    "        heapq.heappush(heap, merged)\n",
    "\n",
    "    return heap[0] if heap else None\n",
    "\n",
    "def generate_huffman_codes(node, prefix=\"\", codebook=None):\n",
    "    if codebook is None:\n",
    "        codebook = {}\n",
    "\n",
    "    if node is not None:\n",
    "        if node.symbol is not None:\n",
    "            codebook[node.symbol] = prefix\n",
    "        generate_huffman_codes(node.left, prefix + \"0\", codebook)\n",
    "        generate_huffman_codes(node.right, prefix + \"1\", codebook)\n",
    "\n",
    "    return codebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvar no arquivo a imagem comprimida/ descomprimir a imagem -  Araju\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data, huffman_codes):\n",
    "    return ''.join(huffman_codes[symbol] for symbol in data)\n",
    "\n",
    "def decode_data(encoded_data, huffman_codes):\n",
    "    reverse_huffman_codes = {v: k for k, v in huffman_codes.items()}\n",
    "    current_code = \"\"\n",
    "    decoded_data = []\n",
    "\n",
    "    for bit in encoded_data:\n",
    "        current_code += bit\n",
    "        if current_code in reverse_huffman_codes:\n",
    "            decoded_data.append(reverse_huffman_codes[current_code])\n",
    "            current_code = \"\"\n",
    "\n",
    "    return decoded_data\n",
    "\n",
    "\n",
    "def save_to_file(original_image_shape, filename, huffman_codes, encoded_data, predictions_options):\n",
    "    with open(filename, 'wb') as file:\n",
    "\n",
    "        # Save the shape of the original image\n",
    "        file.write(struct.pack('<I', original_image_shape[0]))\n",
    "        file.write(struct.pack('<I', original_image_shape[1]))\n",
    "        \n",
    "        # Create a bitarray for predictions options\n",
    "        bits = bitarray(endian='big')\n",
    "        \n",
    "        # Convert each prediction to a 2-bit binary representation\n",
    "        for value in predictions_options:\n",
    "            if value < 0 or value > 3:\n",
    "                raise ValueError(\"Predictions must be between 1 and 3\")\n",
    "            bits.extend(format(value, '02b'))\n",
    "        \n",
    "        # Write the bitarray to the file\n",
    "        bits.tofile(file)\n",
    "        \n",
    "        # Save the number of unique symbols\n",
    "        file.write(struct.pack('<I', len(huffman_codes)))\n",
    "\n",
    "        # Save the Huffman codes\n",
    "        for symbol, code in huffman_codes.items():\n",
    "            file.write(struct.pack('<i', symbol))  # Symbol as 4 bytes\n",
    "            file.write(struct.pack('<B', len(code)))  # Length of the code\n",
    "            file.write(code.encode())  # Code as bytes\n",
    "\n",
    "        # Save the length of the encoded data in bits\n",
    "        file.write(struct.pack('<I', len(encoded_data)))\n",
    "        # Convert the encoded data to bytes\n",
    "        buffer = 0\n",
    "        buffer_length = 0\n",
    "        byte_array = bytearray()\n",
    "\n",
    "        for bit in encoded_data:\n",
    "            buffer = (buffer << 1) | int(bit)\n",
    "            buffer_length += 1\n",
    "\n",
    "            if buffer_length == 8:\n",
    "                byte_array.append(buffer)\n",
    "                buffer = 0\n",
    "                buffer_length = 0\n",
    "\n",
    "        if buffer_length > 0:\n",
    "            buffer <<= (8 - buffer_length)\n",
    "            byte_array.append(buffer)\n",
    "        file.write(byte_array)\n",
    "\n",
    "def load_from_file(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        # Read the shape of the original image\n",
    "        original_image_shape = (struct.unpack('<I', file.read(4))[0], struct.unpack('<I', file.read(4))[0])\n",
    "        \n",
    "        number_of_blocks = math.ceil(original_image_shape[0] * original_image_shape[1] / (BLOCK_SIZE * BLOCK_SIZE))\n",
    "       \n",
    "        # Calculate the number of bits needed for the predictions\n",
    "        num_bits = number_of_blocks * 2\n",
    "        \n",
    "        # Read the necessary number of bytes for the predictions\n",
    "        num_bytes = (num_bits + 7) // 8  # Round up to ensure we read enough bytes\n",
    "        bits = bitarray(endian='big')\n",
    "        bits.fromfile(file, num_bytes)\n",
    "        \n",
    "        # Convert the bitarray back to predictions options\n",
    "        predictions_options = []\n",
    "        for i in range(number_of_blocks):\n",
    "            # Get each 2-bit segment\n",
    "            two_bits = bits[i*2:i*2+2].to01()\n",
    "            # Convert binary string to integer back to [0, 3]\n",
    "            value = int(two_bits, 2)\n",
    "            predictions_options.append(value)\n",
    "        \n",
    "        print(f\" PREDICTIONS_OPTIONS == predictions_options: {PREDICTIONS_OPTIONS == predictions_options}\")\n",
    "        # Read the number of unique symbols\n",
    "        num_symbols = struct.unpack('<I', file.read(4))[0]\n",
    "\n",
    "        # Read the Huffman codes\n",
    "        huffman_codes = {}\n",
    "        for _ in range(num_symbols):\n",
    "            symbol = struct.unpack('<i', file.read(4))[0]\n",
    "            code_length = struct.unpack('<B', file.read(1))[0]\n",
    "            code = file.read(code_length).decode()\n",
    "            huffman_codes[symbol] = code\n",
    "\n",
    "        # Read the length of the encoded data in bits\n",
    "        encoded_data_length = struct.unpack('<I', file.read(4))[0]\n",
    "\n",
    "        # Read the encoded data as bits\n",
    "        encoded_data = ''\n",
    "        while len(encoded_data) < encoded_data_length:\n",
    "            byte = file.read(1)\n",
    "            if not byte:\n",
    "                break\n",
    "            byte_value = ord(byte)\n",
    "            encoded_data += f'{byte_value:08b}'\n",
    "\n",
    "        return original_image_shape, huffman_codes, encoded_data[:encoded_data_length], predictions_options\n",
    "\n",
    "def huffman_encode_matrix(matrix):\n",
    "    flat_list = [item for sublist in matrix for item in sublist]\n",
    "    frequencies = Counter(flat_list)\n",
    "    huffman_tree = build_huffman_tree(frequencies)\n",
    "    huffman_codes = generate_huffman_codes(huffman_tree)\n",
    "    encoded_data = encode_data(flat_list, huffman_codes)\n",
    "    return huffman_codes, encoded_data\n",
    "\n",
    "def huffman_decode_matrix(encoded_data, huffman_codes):\n",
    "    decoded_flat_list = decode_data(encoded_data, huffman_codes)\n",
    "    zigzag_encoded_residuals_with_eob = []\n",
    "    curr_zig_zag = []\n",
    "    for el in decoded_flat_list:\n",
    "        curr_zig_zag.append(el)\n",
    "        if el == SYMBOL_EOB or len(curr_zig_zag) == BLOCK_SIZE * BLOCK_SIZE:\n",
    "            zigzag_encoded_residuals_with_eob.append(curr_zig_zag)\n",
    "            curr_zig_zag = []\n",
    "    return zigzag_encoded_residuals_with_eob, decoded_flat_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tamanho original da imagem\n",
    "# opcao de predicao por macrobloco\n",
    "# dicionario de huffman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Entropia sem rle e sem eob: {calculate_entropy(np.array(zigzag_encoded_residuals))}\")\n",
    "# print(f\"Entropia com eob: {calculate_entropy(zigzag_encoded_residuals_with_eob)}\")\n",
    "# print(f\"Entropia com rle: {calculate_entropy(rle_encoded_residuals)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zigzag_encoded_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zigzag_encoded_residuals_with_eob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rle_encoded_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#huffman_encode_matrix(zigzag_encoded_residuals_with_eob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lists_equal(list1, list2):\n",
    "    if len(list1) != len(list2):\n",
    "        return False\n",
    "    for sublist1, sublist2 in zip(list1, list2):\n",
    "        if sublist1 != sublist2:\n",
    "            return False\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Matrix 8 x 8\n",
    "matrix_to_save = zigzag_quantized_residuals_with_eob#np.random.randint(-300, 300, (8, 8))\n",
    "image_shape = ORIGINAL_IMAGE_SHAPE\n",
    "huffman_codes, encoded_data = huffman_encode_matrix(matrix_to_save)\n",
    "filename = f'{IMAGE_NAME}_compressed.gfa'\n",
    "save_to_file(image_shape, filename, huffman_codes, encoded_data, PREDICTIONS_OPTIONS)\n",
    "\n",
    "loaded_orginal_image_shape, loaded_huffman_codes, loaded_encoded_data, loaded_predictions_options = load_from_file(filename)\n",
    "\n",
    "decoded_matrix, decoded_flat_list = huffman_decode_matrix(loaded_encoded_data, loaded_huffman_codes)\n",
    "print(f\"shape: {image_shape} == {loaded_orginal_image_shape} : {image_shape == loaded_orginal_image_shape}\")\n",
    "print(f\"predictions_options: PREDICTIONS_OPTIONS == loaded_predictions_options : {PREDICTIONS_OPTIONS == loaded_predictions_options}\")\n",
    "print(f\"matrix: matrix_to_save == decoded_matrix : {lists_equal(matrix_to_save, decoded_matrix)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descompressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_zigzag_encoded_residuals_with_eob = decoded_matrix\n",
    "_zig_zags = apply_eob_to_zigzag(_zigzag_encoded_residuals_with_eob)\n",
    "print(f\"{_zig_zags == zigzag_quantized_residuals}\")\n",
    "_quantized_residuals = apply_zigzag_decode(_zig_zags, BLOCK_SIZE, ORIGINAL_IMAGE_SHAPE)\n",
    "_dequantized_residuals = apply_dequantization(_quantized_residuals, BLOCK_SIZE)\n",
    "_residuals_ = apply_image_transformation(_dequantized_residuals, BLOCK_SIZE, get_idct)\n",
    "_reconstructed_image = reconstruct_image(_residuals_, BLOCK_SIZE, loaded_predictions_options)\n",
    "_reconstructed_image = _reconstructed_image.astype(np.float64) + 128\n",
    "plot_image(_reconstructed_image, 'Imagem Reconstruída')\n",
    "print(f\"RMSE : {rmse(_reconstructed_image, ORIGINAL_IMAGE)}\")\n",
    "print(f\"PSNR : {psnr(_reconstructed_image, ORIGINAL_IMAGE)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
